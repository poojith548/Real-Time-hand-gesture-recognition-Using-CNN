<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous"> -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/control_utils/control_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.12.0/dist/tf.min.js" crossorigin="anonymous"></script>
  <!-- <script type="text/javascript" src="https://raw.githubusercontent.com/HarshaSomaraju/gesture-recognition/main/classnames.json"></script> -->
  <!-- <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-node@3.12.0/dist/index.min.js" crossorigin="anonymous"></script> -->
<style>
  /* #output{
    position: absolute;
    right: 60px;
    top: 50%;
  } */

  #output{
    position: absolute;
    right: 60px;
    top: 30px;
    color: red;
  }

  /* .container {
    position: fixed;
    top: 0;
    left: 0;
    border: 12px solid #000;
    width: 100%;
    height: 100%;
    margin: 0;
    padding: 0;
    box-sizing: border-box;
  } */

  /* .container-main {
    border: 12px solid #000;
  } */

  .container-canvas {
      /* This could be done in one single declaration. See the extended sample. */
      margin-right: auto;
      margin-left: auto;
  }

  html,
body {
  width: 100%;
  height: 100%;
  margin: 0px;
  border: 0;
  overflow: hidden;
  /*  Disable scrollbars */
  display: block;
  /* No floating content on sides */
}

</style>
</head>

<script>

  var hr = 1;
  if(/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)){
    hr = 3/5;
  }

  function resize_canvas(){
    const canvasElement = document.getElementsByClassName('output_canvas')[0];
    canvasElement.width  = window.innerWidth;
    // canvasElement.width  = canvasElement.parentElement.offsetWidth;
    canvasElement.height = window.innerHeight*hr;
  }
</script>

<body onresize="resize_canvas()">
  <!-- <div class="container">
    <video class="input_video"></video> 
    <canvas class="output_canvas" width="1280px" height="720px">  <h2>Stop</h2></canvas>
  </div>
  <h2 id='output'></h2> -->

  <div class="continer container-main">
    <div class="container-cnvas ">
      <div>
        <video class="input_video"></video> 
        <canvas class="output_canvas" width="1280px" height="720px"></canvas>
      </div>
      <div>
        <h2 id='output'></h2>
      </div>
    </div>  
  </div>

  <script type="module">
    resize_canvas();
    const model = await tf.loadLayersModel("https://raw.githubusercontent.com/HarshaSomaraju/gesture-recognition/main/model/model.json");
    const labels = ['okay', 'peace', 'thumbs up', 'thumbs down', 'call me', 'stop', 'rock', 'live long', 'fist', 'smile'];
    const outputElement = document.getElementById('output');
    const videoElement = document.getElementsByClassName('input_video')[0];
    videoElement.style.display = 'none';
    const canvasElement = document.getElementsByClassName('output_canvas')[0];
    const canvasCtx = canvasElement.getContext('2d');
    
    function onResults(results) {
      canvasCtx.save();
      canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
      canvasCtx.drawImage(
          results.image, 0, 0, canvasElement.width, canvasElement.height);
      if (results.multiHandLandmarks) {
        for (const landmarks of results.multiHandLandmarks) {
          var lds = [[]];
          for(const lm of landmarks) {
            var lmx = lm.x * canvasElement.width;
            var lmy = lm.y * canvasElement.height;
            lds[0].push([lmx, lmy]);
          }
          var tflds = tf.tensor(lds);
          // console.log(tflds);
          const prediction = model.predict(tflds);
          // prediction.as1D().argMax().print();
          const pred = prediction.as1D().argMax().dataSync()[0];
          // console.log('Prediction is: ');
          // console.log(labels[pred]);
          outputElement.innerText = labels[pred];
          drawConnectors(canvasCtx, landmarks, HAND_CONNECTIONS,
                         {color: '#00FF00', lineWidth: 5});
          drawLandmarks(canvasCtx, landmarks, {color: '#FF0000', lineWidth: 2});
        }
      }
      else{
        outputElement.innerText = '';
      }
      canvasCtx.restore();
    }
    
    const hands = new Hands({locateFile: (file) => {
      return `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`;
    }});
    hands.setOptions({
      maxNumHands: 2,
      modelComplexity: 1,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });
    hands.onResults(onResults);
    var a;
    
    const camera = new Camera(videoElement, {
      onFrame: async () => {
        await hands.send({image: videoElement});
        // const handler = tfnode.io.fileSystem('model.json');
        // const model = await tf.loadLayersModel("https://raw.githubusercontent.com/HarshaSomaraju/gesture-recognition/main/model/model.json");
        // const example = tf.browser.fromPixels(videoElement);
        // const prediction = model.predict(example);
        // console.log('Prediction is: ');
        // console.log(prediction);
      },
      width: window.innerWidth,
      height: window.innerHeight*hr
    });
    camera.start();
    
  </script>
  <!-- <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script> -->
</body>
</html>